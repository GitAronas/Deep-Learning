{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b248d35e",
   "metadata": {
    "id": "b248d35e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a83728",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2a83728",
    "outputId": "858c4795-70b2-4987-8cea-0f7519900223"
   },
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
    "\n",
    "print('x_train max value:', x_train[0].max())\n",
    "print('x_train min value:', x_train[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d4b2f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "58d4b2f4",
    "outputId": "e9474c4e-9b61-487b-a63f-5ec1ccb1a980"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 10)\n",
    "plt.figure(figsize=(5, 10))\n",
    "fig.tight_layout(pad=-1)\n",
    "\n",
    "a = 0\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(10):\n",
    "        axs[i, j].imshow(tf.squeeze(x_test[a]))\n",
    "        axs[i, j].xaxis.set_visible(False)\n",
    "        axs[i, j].yaxis.set_visible(False)\n",
    "        a += 1\n",
    "        plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a82951d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a82951d",
    "outputId": "25bcc8a1-7a0f-4ca7-9e94-41d5fe95c83b"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4673516",
   "metadata": {
    "id": "b4673516"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.6\n",
    "\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape)\n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a448029",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 499
    },
    "id": "8a448029",
    "outputId": "03ca79cd-091b-43af-e83e-ef77580e5ad9"
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "plt.figure(figsize=(20, 8))\n",
    "\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.title('original', size=20)\n",
    "    plt.imshow(tf.squeeze(x_test[i]))\n",
    "    plt.gray()\n",
    "    \n",
    "    bx = plt.subplot(2, n, n + i + 1)\n",
    "    plt.title('original + noise', size=20)\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0831f1e",
   "metadata": {
    "id": "e0831f1e"
   },
   "outputs": [],
   "source": [
    "class Denoise(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Denoise, self).__init__()\n",
    "        \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            Input(shape=(28, 28, 1)),\n",
    "            Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "            Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            Conv2DTranspose(8, kernel_size=3, activation='relu', padding='same', strides=2),\n",
    "            Conv2DTranspose(16, kernel_size=3, activation='relu', padding='same', strides=2),\n",
    "            Conv2D(1, (3, 3), activation='sigmoid', padding='same')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208d6c45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "208d6c45",
    "outputId": "51d63ed5-de77-4b62-92a4-0dab6c805823"
   },
   "outputs": [],
   "source": [
    "autoencoder = Denoise()\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "autoencoder.fit(x_train_noisy,\n",
    "                x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb955d3",
   "metadata": {
    "id": "9cb955d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1128e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "cd1128e4",
    "outputId": "06373cd6-16ca-4f77-81ef-02a42a1fe279",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "for i in range(n):\n",
    "  # display original + noise\n",
    "  bx = plt.subplot(3, n, i + 1)\n",
    "  plt.title(\"original + noise\")\n",
    "  plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "  # display reconstruction\n",
    "  cx = plt.subplot(3, n, i + n + 1)\n",
    "  plt.title(\"reconstructed\")\n",
    "  plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
    "  plt.gray()\n",
    "  bx.get_xaxis().set_visible(False)\n",
    "  bx.get_yaxis().set_visible(False)\n",
    "  # display original\n",
    "  ax = plt.subplot(3, n, i + 2*n + 1)\n",
    "  plt.title(\"original\")\n",
    "  plt.imshow(tf.squeeze(x_test[i]))\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e21b3",
   "metadata": {
    "id": "e6fb2444"
   },
   "source": [
    "Adapted from Intro to Autoencoders, TensorFlow, available on www.tensorflow.org/tutorials/generative/autoencoder"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Image Denoising with Autoencoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
